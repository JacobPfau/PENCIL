{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     40,
     68,
     82,
     95,
     106,
     133,
     148
    ]
   },
   "outputs": [],
   "source": [
    "from resnet import resnet32\n",
    "from cifar import get_cifar10\n",
    "import utils \n",
    "import pencil as pencil_lib\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from scipy.special import softmax\n",
    "\n",
    "import copy as cp\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "if True: # Define hyper parameters\n",
    "    epochs = 320\n",
    "    batch_size = 128\n",
    "    lr = 0.06\n",
    "    momentum = 0.9\n",
    "    weight_decay = 10e-4\n",
    "    n_classes = 10\n",
    "    pencil_epochs = [70, 130, 120]\n",
    "    pencil_lrs = [0.06, 0.06, 0.06]\n",
    "    pencil_alpha, pencil_beta, pencil_gamma = 0.1, 0.4, 600\n",
    "    pencil_KL = True\n",
    "    pencil_K = 10\n",
    "    checkpoint = 5\n",
    "    start_epoch = 0\n",
    "    seed = 1\n",
    "    train_ratio = 0.9\n",
    "    asym_noise = True\n",
    "    noise_ratio = 0.2\n",
    "    temp_path = 'PATH_HERE'\n",
    "    cifar_path = './../data'\n",
    "\n",
    "if True: # Define dataset and transforms\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    np.random.seed(seed)\n",
    "    trainset, valset = get_cifar10(cifar_path, train_ratio=train_ratio, asym=asym_noise, percent=noise_ratio, train=True, download=False, transform_train=transform_train,\n",
    "                                               transform_val=transform_val)\n",
    "    if start_epoch==0: # \n",
    "        print('trainset',len(trainset))\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "########## Model checkpointing commented out\n",
    "#         with open(temp_path+\"trainloader\"+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(trainloader,file)\n",
    "#         with open(temp_path+\"valloader\"+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(valloader,file)\n",
    "#     else: \n",
    "#         with open(temp_path+\"trainloader\"+\".pkl\", \"rb\") as file:\n",
    "#             trainloader = pickle.load(file)\n",
    "#         with open(temp_path+\"valloader\"+\".pkl\", \"rb\") as file:\n",
    "#             valloader = pickle.load(file)\n",
    "\n",
    "if True: # Define Model and optimizer\n",
    "\n",
    "    # Model\n",
    "    print(\"==> creating preact_resnet\")\n",
    "    model = resnet32()\n",
    "    model = model.cuda()\n",
    "    print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "if True: # Define dict for storing results\n",
    "    results = {'train':None,'val':None}\n",
    "    metrics = ['acc','auprc','auroc','loss']\n",
    "    for subset in results.keys(): \n",
    "        results[subset] = {metric:[] for metric in metrics}\n",
    "\n",
    "    results['pencil_labels'], results['labels'], results['true_labels'] = [], [], []\n",
    "    results['pencil_label_drift'], results['pencil_label_correct'] = [], []\n",
    "    for i in range(len(trainset)): \n",
    "        item = trainset.__getitem__(i)\n",
    "        results['labels'].append(item[1])\n",
    "        results['true_labels'].append(item[3])\n",
    "        \n",
    "if True: # Define PENCIL\n",
    "    pencil = pencil_lib.PENCIL(torch.tensor(results['labels']), len(trainset), n_classes, pencil_epochs, pencil_lrs, \n",
    "                                               pencil_alpha, pencil_beta, pencil_gamma, save_losses=True, use_KL=pencil_KL, K=pencil_K)\n",
    "\n",
    "########## Model checkpointing commented out\n",
    "# if start_epoch>0: # Load checkpoint data\n",
    "#     model.load_state_dict(torch.load(temp_path+'epoch'+str(start_epoch)))\n",
    "#     with open(temp_path+\"results\"+str(start_epoch)+\".pkl\", \"rb\") as file:\n",
    "#         results = pickle.load(file)\n",
    "#     with open(temp_path+\"pencil\"+str(start_epoch)+\".pkl\", \"rb\") as file:\n",
    "#         pencil = pickle.load(file)\n",
    "#     pencil.alpha=pencil_alpha\n",
    "#     pencil.beta=pencil_beta\n",
    "    \n",
    "for epoch in range(start_epoch,epochs):\n",
    "    if True: # Train \n",
    "        pencil.set_lr(optimizer, epoch)\n",
    "        model.train()\n",
    "        preds, label_list = [], []\n",
    "        if epoch in pencil_epochs: results['pencil_labels'].append(cp.deepcopy(pencil.y_tilde))\n",
    "\n",
    "        for batch_idx, (inputs, labels, inds, gtrue_labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = pencil.get_loss(epoch, outputs, labels, inds)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pencil.update_y_tilde(epoch, inds)\n",
    "            preds.append(outputs.detach())\n",
    "            label_list.append(labels.cpu())\n",
    "\n",
    "        label_list = np.vstack(torch.cat(label_list).numpy())\n",
    "        preds = softmax(np.vstack(torch.cat(preds).cpu().numpy()), axis=1)\n",
    "        train_results = utils.get_performance_metrics(num_classes=n_classes,preds=preds,label_list=label_list)\n",
    "        for result in train_results.keys():\n",
    "            results['train'][result].append(train_results[result])\n",
    "        label_drift = round(sum(results['labels']==np.argmax(pencil.y_tilde,axis=1))/len(results['labels']),4)\n",
    "        label_true_corr = round(sum(results['true_labels']==np.argmax(pencil.y_tilde,axis=1))/len(results['true_labels']),4)\n",
    "        results['pencil_label_drift'].append(label_drift)\n",
    "        results['pencil_label_correct'].append(label_true_corr)\n",
    "    \n",
    "    if True: # Val\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(valloader):\n",
    "                inputs, labels = inputs.cuda(), labels\n",
    "                outputs = model(inputs)\n",
    "                val_preds.append(outputs)\n",
    "                val_labels.append(labels)\n",
    "        val_labels = np.vstack(torch.cat(val_labels).numpy())\n",
    "        val_preds = softmax(np.vstack(torch.cat(val_preds).cpu().numpy()), axis=1)\n",
    "        val_results = utils.get_performance_metrics(num_classes=n_classes,preds=val_preds,label_list=val_labels)\n",
    "        for result in val_results.keys():\n",
    "            results['val'][result].append(val_results[result])\n",
    "\n",
    "    if True: # Print results \n",
    "        print('Epoch', epoch, 'Current LR', round(optimizer.param_groups[0]['lr'],5))\n",
    "        if epoch>=pencil_epochs[0]:\n",
    "            print('Percent of estimated labels that have remained the same since end of phase 1',round(sum(np.argmax(results['pencil_labels'][0],axis=1)==np.argmax(pencil.y_tilde,axis=1))/len(results['pencil_labels'][0]),4))\n",
    "        print('% y_tilde equal to noisy label',results['pencil_label_drift'][-1])\n",
    "        print('% y_tilde equal to true label',results['pencil_label_correct'][-1])\n",
    "        print('Train acc %.3f, Train auroc %.3f' % (results['train']['acc'][-1], results['train']['auroc'][-1]))\n",
    "        print('Val acc %.3f, Val auroc %.3f' % (results['val']['acc'][-1], results['val']['auroc'][-1]))                                                                 \n",
    "\n",
    "########## Model checkpointing commented out\n",
    "#     if checkpoint!=None and (epoch%checkpoint==0 or epoch+1 in pencil_epochs): #Save model for this epoch\n",
    "#         if epoch%checkpoint==0 and epoch>start_epoch+checkpoint: \n",
    "#             os.remove(temp_path+'epoch'+str(epoch-checkpoint))\n",
    "#             os.remove(temp_path+\"results\"+str(epoch-checkpoint)+\".pkl\")\n",
    "#             os.remove(temp_path+\"pencil\"+str(epoch-checkpoint)+\".pkl\")\n",
    "#         torch.save(model.state_dict(), temp_path+'epoch'+str(epoch))\n",
    "#         with open(temp_path+\"results\"+str(epoch)+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(results,file)\n",
    "#         with open(temp_path+\"pencil\"+str(epoch)+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(pencil,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
