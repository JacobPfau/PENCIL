{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     40,
     68,
     82,
     95,
     106,
     133,
     148
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 45000 Val: 5000\n",
      "trainset 45000\n",
      "==> creating preact_resnet\n",
      "Total params: 0.47M\n",
      "Epoch 0 Current LR 0.06\n",
      "% y_tilde equal to noisy label 1.0\n",
      "% y_tilde equal to true label 0.9\n",
      "Train acc 0.359, Train auroc 0.819\n",
      "Val acc 0.386, Val auroc 0.862\n",
      "Epoch 1 Current LR 0.06\n",
      "% y_tilde equal to noisy label 1.0\n",
      "% y_tilde equal to true label 0.9\n",
      "Train acc 0.530, Train auroc 0.898\n",
      "Val acc 0.443, Val auroc 0.865\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2bc161edd399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpencil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mpencil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_y_tilde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/good_env/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/good_env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from resnet import resnet32\n",
    "from cifar import get_cifar10\n",
    "import utils \n",
    "import pencil as pencil_lib\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from scipy.special import softmax\n",
    "\n",
    "import copy as cp\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "if True: # Define hyper parameters\n",
    "    epochs = 320\n",
    "    batch_size = 128\n",
    "    lr = 0.06\n",
    "    momentum = 0.9\n",
    "    weight_decay = 10e-4\n",
    "    n_classes = 10\n",
    "    pencil_epochs = [70, 130, 120]\n",
    "    pencil_lrs = [0.06, 0.06, 0.06]\n",
    "    pencil_alpha, pencil_beta, pencil_gamma = 0.1, 0.4, 600\n",
    "    pencil_KL = True\n",
    "    pencil_K = 10\n",
    "    checkpoint = 5\n",
    "    start_epoch = 0\n",
    "    seed = 1\n",
    "    train_ratio = 0.9\n",
    "    asym_noise = True\n",
    "    noise_ratio = 0.2\n",
    "    temp_path = 'PATH_HERE'\n",
    "    cifar_path = './../data'\n",
    "\n",
    "if True: # Define dataset and transforms\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    np.random.seed(seed)\n",
    "    trainset, valset = get_cifar10(cifar_path, train_ratio=train_ratio, asym=asym_noise, percent=noise_ratio, train=True, download=False, transform_train=transform_train,\n",
    "                                               transform_val=transform_val)\n",
    "    if start_epoch==0: # \n",
    "        print('trainset',len(trainset))\n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "#         with open(temp_path+\"trainloader\"+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(trainloader,file)\n",
    "#         with open(temp_path+\"valloader\"+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(valloader,file)\n",
    "#     else: \n",
    "#         with open(temp_path+\"trainloader\"+\".pkl\", \"rb\") as file:\n",
    "#             trainloader = pickle.load(file)\n",
    "#         with open(temp_path+\"valloader\"+\".pkl\", \"rb\") as file:\n",
    "#             valloader = pickle.load(file)\n",
    "\n",
    "if True: # Define Model and training hyper parameters\n",
    "\n",
    "    # Model\n",
    "    print(\"==> creating preact_resnet\")\n",
    "    model = resnet32()\n",
    "    model = model.cuda()\n",
    "    print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "#     PENCIL\n",
    "    pencil = pencil_lib.PENCIL(len(trainset), n_classes, pencil_epochs, pencil_lrs, \n",
    "                                               pencil_alpha, pencil_beta, pencil_gamma, save_losses=True, use_KL=pencil_KL, K=pencil_K)\n",
    "\n",
    "if True: # Define dict and list for storing results\n",
    "    results = {'train':None,'val':None}\n",
    "    metrics = ['acc','auprc','auroc','loss']\n",
    "    for subset in results.keys(): \n",
    "        results[subset] = {metric:[] for metric in metrics}\n",
    "\n",
    "    results['pencil_labels'], results['labels'], results['true_labels'] = [], [], []\n",
    "    results['pencil_label_drift'], results['pencil_label_correct'] = [], []\n",
    "    for i in range(len(trainset)): \n",
    "        item = trainset.__getitem__(i)\n",
    "        results['labels'].append(item[1])\n",
    "        results['true_labels'].append(item[3])\n",
    "\n",
    "if start_epoch>0: # Load checkpoint data\n",
    "    model.load_state_dict(torch.load(temp_path+'epoch'+str(start_epoch)))\n",
    "    with open(temp_path+\"results\"+str(start_epoch)+\".pkl\", \"rb\") as file:\n",
    "        results = pickle.load(file)\n",
    "    with open(temp_path+\"pencil\"+str(start_epoch)+\".pkl\", \"rb\") as file:\n",
    "        pencil = pickle.load(file)\n",
    "    pencil.alpha=pencil_alpha\n",
    "    pencil.beta=pencil_beta\n",
    "    \n",
    "for epoch in range(start_epoch,epochs):\n",
    "    \n",
    "    if True: # Train \n",
    "        pencil.set_lr(optimizer, epoch)\n",
    "        model.train()\n",
    "        preds, label_list = [], []\n",
    "        if epoch in pencil_epochs: results['pencil_labels'].append(cp.deepcopy(pencil.y_tilde))\n",
    "\n",
    "        for batch_idx, (inputs, labels, inds, gtrue_labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs = model(inputs)\n",
    "            loss = pencil.get_loss(epoch, outputs, labels, inds)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pencil.update_y_tilde(epoch, inds)\n",
    "            preds.append(outputs.detach())\n",
    "            label_list.append(labels.cpu())\n",
    "\n",
    "        label_list = np.vstack(torch.cat(label_list).numpy())\n",
    "        preds = softmax(np.vstack(torch.cat(preds).cpu().numpy()), axis=1)\n",
    "        train_results = utils.get_performance_metrics(num_classes=n_classes,preds=preds,label_list=label_list)\n",
    "        for result in train_results.keys():\n",
    "            results['train'][result].append(train_results[result])\n",
    "        label_drift = round(sum(results['labels']==np.argmax(pencil.y_tilde,axis=1))/len(results['labels']),4)\n",
    "        label_true_corr = round(sum(results['true_labels']==np.argmax(pencil.y_tilde,axis=1))/len(results['true_labels']),4)\n",
    "        results['pencil_label_drift'].append(label_drift)\n",
    "        results['pencil_label_correct'].append(label_true_corr)\n",
    "    \n",
    "    if True: # Val\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (inputs, labels) in enumerate(valloader):\n",
    "                inputs, labels = inputs.cuda(), labels\n",
    "                outputs = model(inputs)\n",
    "                val_preds.append(outputs)\n",
    "                val_labels.append(labels)\n",
    "        val_labels = np.vstack(torch.cat(val_labels).numpy())\n",
    "        val_preds = softmax(np.vstack(torch.cat(val_preds).cpu().numpy()), axis=1)\n",
    "        val_results = utils.get_performance_metrics(num_classes=n_classes,preds=val_preds,label_list=val_labels)\n",
    "        for result in val_results.keys():\n",
    "            results['val'][result].append(val_results[result])\n",
    "\n",
    "    if True: # print results \n",
    "        print('Epoch', epoch, 'Current LR', round(optimizer.param_groups[0]['lr'],5))\n",
    "        if epoch>=pencil_epochs[0]:\n",
    "            print('Percent of estimated labels that have remained the same since end of phase 1',round(sum(np.argmax(results['pencil_labels'][0],axis=1)==np.argmax(pencil.y_tilde,axis=1))/len(results['pencil_labels'][0]),4))\n",
    "        print('% y_tilde equal to noisy label',results['pencil_label_drift'][-1])\n",
    "        print('% y_tilde equal to true label',results['pencil_label_correct'][-1])\n",
    "        print('Train acc %.3f, Train auroc %.3f' % (results['train']['acc'][-1], results['train']['auroc'][-1]))\n",
    "        print('Val acc %.3f, Val auroc %.3f' % (results['val']['acc'][-1], results['val']['auroc'][-1]))                                                                 \n",
    "         \n",
    "#     if checkpoint!=None and (epoch%checkpoint==0 or epoch+1 in pencil_epochs): #Save model for this epoch\n",
    "#         if epoch%checkpoint==0 and epoch>start_epoch+checkpoint: \n",
    "#             os.remove(temp_path+'epoch'+str(epoch-checkpoint))\n",
    "#             os.remove(temp_path+\"results\"+str(epoch-checkpoint)+\".pkl\")\n",
    "#             os.remove(temp_path+\"pencil\"+str(epoch-checkpoint)+\".pkl\")\n",
    "#         torch.save(model.state_dict(), temp_path+'epoch'+str(epoch))\n",
    "#         with open(temp_path+\"results\"+str(epoch)+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(results,file)\n",
    "#         with open(temp_path+\"pencil\"+str(epoch)+\".pkl\", \"wb\") as file:\n",
    "#             pickle.dump(pencil,file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
